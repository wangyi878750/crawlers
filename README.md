#写爬虫很简单但也很难

写作上，我真是个很随性的人，挖再多的坑都不一定会去补上，反正读者也没一直催...正因为随性，我才说过曾经写的那本书的经历实在是痛苦，虽然写完后给我带来的好处还是很多的。也是因为随性，将公众号沉静了个把月，发神经去写博客 evilcos.me，一写还写了好几篇。博客上主要还是技术，这是本，改不了。而公众号，技术点谈太深就不行了，更多还是科普及观点相关的文字。

我的读者们，尤其是收听这么久我公众号的读者们，你们估计已经习惯我这样的风格了，那请继续保持习惯...你以为“懒人在思考”这个名字是怎么来的，就是因为懒，说好听点是“随性”:D

回归正题，我填下坑。

前两篇文章大家可以温习下：
新人上手 Python 另类建议——被和谐了的答案
爬虫 Tip 相关与不相关的几点补充

为什么说写爬虫很简单，你看源码：
https://github.com/evilcos/crawlers

如果你按我前两篇文章说的，基于 Scrapy 写爬虫，那么我开源的这个小爬虫你可以直接参考：crawl3 目录下可以翻到 rosi.py，专门爬 rosioo.com 这个站的美女图片。这样运行：

1. 按照官方文档安装 Scrapy
https://doc.scrapy.org/en/1.2/intro/install.html

2. git clone https://github.com/evilcos/crawlers

3. 创建个 /data/rosi/ 目录，用于保存下载的图片，当然这个路径可以在 settings.py 里修改

4. 进入 crawl3 目录，运行命令：scrapy crawl rosi

5. 没了

这份代码确实很少，也很简单且粗暴，但我估计能真的领悟深刻的人会很少。

我交代下我的爬虫生涯吧，2008年开始就写爬虫到现在，过程也发现了 Scrapy 等爬虫框架，但那时都太初始了，哪有现在用得这样爽？而我因为后来负责公司的漏洞扫描器引擎的编写，爬虫是我最费力写出来的，从零踏了无数坑，fix 了无数 bugs。回头看看 N 年前自己写的大爬虫，复杂到我想吐，估计后来那些参与维护我写的那个大爬虫的同学会恨死我...其实这不完全怪我呀，爬虫本就是个非常复杂的玩意，因为其面对的 Web 环境复杂度太高，我随便罗列些必定会踏到的坑吧：

字符集编码
HTML/XML不规范
链接伪协议及不规范
各种文件类型
网页跳转：服务端、客户端（Meta、JavaScript、Flash等）
Cookie/认证会话维护
代理维护
GPC(Cookie/Post/Get)参数提取
HTTP多种请求
超时：连接超时/读取超时
JavaScript动态出来的链接
AJAX请求
链接爬取去重算法
广度深度算法
并发：进程/线程/协程
调度：同步/异步
各种内存优化
各种异常维护
灵活配置
灵活扩展
优秀的文档...

我可以肯定是我现在由于赶时间，并没都罗列全面。经历过这些的人才会感慨：工程化能力的重要性啊...

你看，我上面开源的那个 Scrapy 小爬虫是多么的简单，然而，我强烈建议：
当你在享受这种快感的时候，去深度理解理解下，这种快感的由来吧。

我愿意花钱去赞助一些优秀开源甚至花高价钱去买一些优秀工具，虽然我没钱。促使我这样做，以及不断学习的本质是：我感受到那种敬畏。

赶时间，这篇先这样，有空继续。如果你跟上了，欢迎邮件我：evilcos@gmail.com，邮件肯定看，由于精力问题，我不一定回复，请理解。

-----------------
微信公众号「Lazy-Thought」
几个黑客在维护，都很懒，都想改变点什么
